{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP process\n",
    "1. Segmentation\n",
    "2. Tokenizing\n",
    "3. Stop words\n",
    "4. Stemming (-ing -s -ed)\n",
    "5. Lemmatization(am are is : be)\n",
    "6. Speech Tagging (noun, verb, preposition...)\n",
    "7. Named Entity Tagging (location, name...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dir\n",
    "work_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(work_dir, \"INPUT/all_speeches.csv\")\n",
    "speeches_data = pd.read_csv(input_path)\n",
    "speeches_data[\"date\"] = pd.to_datetime(speeches_data[\"date\"],format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 100 row for test\n",
    "#df_raw = speeches_data.sample(n = 100)\n",
    "\n",
    "# selected latest 100 row\n",
    "df_raw = speeches_data.sort_values(\"date\").tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 keyBERT: key words extraction\n",
    "\n",
    "? add Stemming\n",
    "? n-gram(1,3) 3-gram phases can also be vectorized by KeyphraseVectorizers\n",
    "KeyphraseVectorizers is a recently released package which can be used in addition to KeyBERT to extract enhanced keyphrases from text documents. This approach eliminates the need for user defined word n-gram ranges and extracts grammatically correct keyphrases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keyphrase_vectorizers\n",
      "  Using cached keyphrase_vectorizers-0.0.11-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.8/site-packages (from keyphrase_vectorizers) (1.22.2)\n",
      "Collecting nltk>=3.6.1\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting spacy-transformers>=1.1.6\n",
      "  Using cached spacy_transformers-1.2.1-cp38-cp38-macosx_10_9_x86_64.whl (175 kB)\n",
      "Collecting spacy>=3.0.1\n",
      "  Using cached spacy-3.5.0-cp38-cp38-macosx_10_9_x86_64.whl (6.8 MB)\n",
      "Collecting psutil>=5.8.0\n",
      "  Using cached psutil-5.9.4-cp36-abi3-macosx_10_9_x86_64.whl (243 kB)\n",
      "Collecting scikit-learn>=1.0\n",
      "  Using cached scikit_learn-1.2.1-cp38-cp38-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from keyphrase_vectorizers) (1.10.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.10.31-cp38-cp38-macosx_10_9_x86_64.whl (294 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.6.1->keyphrase_vectorizers) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.6.1->keyphrase_vectorizers) (4.47.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.6.1->keyphrase_vectorizers) (0.16.0)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
      "  Using cached spacy_alignments-0.9.0-cp38-cp38-macosx_10_9_x86_64.whl (319 kB)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy-transformers>=1.1.6->keyphrase_vectorizers) (1.10.1)\n",
      "Requirement already satisfied: transformers<4.27.0,>=3.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy-transformers>=1.1.6->keyphrase_vectorizers) (4.26.0)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Using cached srsly-2.4.5-cp38-cp38-macosx_10_9_x86_64.whl (489 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp38-cp38-macosx_10_9_x86_64.whl (107 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.4-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=3.0.1->keyphrase_vectorizers) (2.24.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=3.0.1->keyphrase_vectorizers) (6.3.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp38-cp38-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.7-cp38-cp38-macosx_10_9_x86_64.whl (763 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=3.0.1->keyphrase_vectorizers) (20.4)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=3.0.1->keyphrase_vectorizers) (2.11.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy>=3.0.1->keyphrase_vectorizers) (49.2.0.post20200714)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=1.0->keyphrase_vectorizers) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->spacy-transformers>=1.1.6->keyphrase_vectorizers) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase_vectorizers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase_vectorizers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase_vectorizers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<4.27.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase_vectorizers) (0.12.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase_vectorizers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase_vectorizers) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase_vectorizers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase_vectorizers) (2020.6.20)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp38-cp38-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=3.0.1->keyphrase_vectorizers) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=3.0.1->keyphrase_vectorizers) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy>=3.0.1->keyphrase_vectorizers) (1.1.1)\n",
      "\u001b[31mERROR: spyder 4.1.4 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 4.1.4 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: scikit-learn 1.2.1 has requirement joblib>=1.1.1, but you'll have joblib 0.16.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pynndescent 0.5.8 has requirement numba>=0.51.2, but you'll have numba 0.50.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: regex, nltk, spacy-alignments, catalogue, srsly, langcodes, cymem, murmurhash, preshed, spacy-loggers, pydantic, spacy-legacy, typer, wasabi, blis, confection, thinc, pathy, spacy, spacy-transformers, psutil, scikit-learn, keyphrase-vectorizers\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2020.6.8\n",
      "    Uninstalling regex-2020.6.8:\n",
      "      Successfully uninstalled regex-2020.6.8\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.5\n",
      "    Uninstalling nltk-3.5:\n",
      "      Successfully uninstalled nltk-3.5\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.7.0\n",
      "    Uninstalling psutil-5.7.0:\n",
      "      Successfully uninstalled psutil-5.7.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 keyphrase-vectorizers-0.0.11 langcodes-3.3.0 murmurhash-1.0.9 nltk-3.8.1 pathy-0.10.1 preshed-3.0.8 psutil-5.9.4 pydantic-1.10.4 regex-2022.10.31 scikit-learn-1.2.1 spacy-3.5.0 spacy-alignments-0.9.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 spacy-transformers-1.2.1 srsly-2.4.5 thinc-8.1.7 typer-0.7.0 wasabi-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keyphrase_vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyBERT(text,keyphrase_ngram_range,top_n):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(\n",
    "                      text,\n",
    "                      keyphrase_ngram_range=keyphrase_ngram_range, \n",
    "                      # use_maxsum=True,\n",
    "                      # use_mmr=True, \n",
    "                      # diversity=0.7,\n",
    "                      # nr_candidates=20, \n",
    "                      top_n=top_n)\n",
    "  \n",
    "    li_keywords = [pair[0] for pair in keywords] # keywords list without similarity value\n",
    "\n",
    "    return li_keywords\n",
    "\n",
    "def keyBERT_kv(text):\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(docs=text, vectorizer=KeyphraseCountVectorizer()) # stop word?\n",
    "    li_keywords = [pair[0] for pair in keywords] # keywords list without similarity value\n",
    "    \n",
    "    return li_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_01 = df_raw.copy()\n",
    "#1. compare keyphrase_ngram_range of 1,2,3\n",
    "df_keywords_01[\"keywords_1\"] = df_keywords_01[\"text\"].apply(lambda x: keyBERT(x,(1, 1),5))\n",
    "df_keywords_01[\"keywords_2\"] = df_keywords_01[\"text\"].apply(lambda x: keyBERT(x,(2, 2),5))\n",
    "df_keywords_01[\"keywords_3\"] = df_keywords_01[\"text\"].apply(lambda x: keyBERT(x,(3, 3),5))\n",
    "df_keywords_01[\"keywords\"] = df_keywords_01[\"text\"].apply(lambda x: keyBERT_kv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>is_gov</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords_1</th>\n",
       "      <th>keywords_2</th>\n",
       "      <th>keywords_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>r220620b_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>NO_INFO</td>\n",
       "      <td>lane</td>\n",
       "      <td>0</td>\n",
       "      <td>Notes: The vertical line indicates the start o...</td>\n",
       "      <td>[hicp, forecast, gdp, hicpx, forecasts]</td>\n",
       "      <td>[hicpx quarterly, model hicp, hicp energy, hic...</td>\n",
       "      <td>[hicp energy prices, hicp hicpx quarterly, hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>r220620a_BOE</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>UK monetary policy in the context of global sp...</td>\n",
       "      <td>mann</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to this presentation of the May . The ...</td>\n",
       "      <td>[inflation, inflationary, shocks, monetary, ec...</td>\n",
       "      <td>[shocks russia, shocks global, supply shocks, ...</td>\n",
       "      <td>[large shocks russia, shocks russia invasion, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>r220620a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>Hearing of the Committee on Economic and Monet...</td>\n",
       "      <td>lagarde</td>\n",
       "      <td>1</td>\n",
       "      <td>It is a pleasure to be here again for our seco...</td>\n",
       "      <td>[euro, eurosystem, monetary, brussels, sanctions]</td>\n",
       "      <td>[affecting euro, monetary policy, relevant eur...</td>\n",
       "      <td>[facing monetary policy, severely affecting eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>r220621a_BOA</td>\n",
       "      <td>australia</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Inflation and Monetary Policy</td>\n",
       "      <td>lowe</td>\n",
       "      <td>1</td>\n",
       "      <td>I would like to thank AMCHAM for the invitatio...</td>\n",
       "      <td>[inflation, inflationary, monetary, yield, cpi]</td>\n",
       "      <td>[current inflationary, ongoing inflation, rece...</td>\n",
       "      <td>[responding higher inflation, inflation austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>r220622a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>Good, bad and hopeful news: the latest on the ...</td>\n",
       "      <td>elderson</td>\n",
       "      <td>0</td>\n",
       "      <td>I understand that today's audience includes ma...</td>\n",
       "      <td>[ecb, risks, risk, crises, climate]</td>\n",
       "      <td>[risks climate, risks banks, practices ecb, cl...</td>\n",
       "      <td>[risk management ecb, risks practices ecb, ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>r221102a_BOC</td>\n",
       "      <td>canada</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>Preparing for payments supervision</td>\n",
       "      <td>morrow</td>\n",
       "      <td>0</td>\n",
       "      <td>Good morning, and thank you for inviting me to...</td>\n",
       "      <td>[banks, bank, fintech, payments, payment]</td>\n",
       "      <td>[payments fintech, bank canada, finance canada...</td>\n",
       "      <td>[bank canada evolving, payments ecosystem cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>r221103a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>Mind the step: calibrating monetary policy in ...</td>\n",
       "      <td>panetta</td>\n",
       "      <td>0</td>\n",
       "      <td>The euro area is facing a sequence of unpreced...</td>\n",
       "      <td>[inflationary, inflation, euro, eurosystem, mo...</td>\n",
       "      <td>[inflation euro, risks inflation, risks euro, ...</td>\n",
       "      <td>[euro reinforcing inflationary, risks inflatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>r221104b_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>The euro area economy and the energy transition</td>\n",
       "      <td>guindos</td>\n",
       "      <td>0</td>\n",
       "      <td>I am very pleased to be taking part in this ev...</td>\n",
       "      <td>[inflation, macroeconomic, inflationary, econo...</td>\n",
       "      <td>[energy inflation, economy following, economy ...</td>\n",
       "      <td>[inflation rising energy, euro area economy, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>r221104a_ECB</td>\n",
       "      <td>euro area</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>Monetary policy in a high inflation environmen...</td>\n",
       "      <td>lagarde</td>\n",
       "      <td>1</td>\n",
       "      <td>Inflation in the euro area is far too high, re...</td>\n",
       "      <td>[inflation, inflationary, monetary, recessions...</td>\n",
       "      <td>[estonia inflation, exacerbate inflationary, i...</td>\n",
       "      <td>[inflation entrenched euro, estonia inflation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>r221110a_SNB</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>Current challenges to central banks' independence</td>\n",
       "      <td>jordan</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladies and gentlemen I am very grateful for th...</td>\n",
       "      <td>[macroeconomic, economists, economics, banks, ...</td>\n",
       "      <td>[central banks, banks independence, bank indep...</td>\n",
       "      <td>[central banks independence, central bank inde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reference         country       date  \\\n",
       "3221  r220620b_ECB       euro area 2022-06-20   \n",
       "6114  r220620a_BOE  united kingdom 2022-06-20   \n",
       "3220  r220620a_ECB       euro area 2022-06-20   \n",
       "279   r220621a_BOA       australia 2022-06-21   \n",
       "3222  r220622a_ECB       euro area 2022-06-22   \n",
       "...            ...             ...        ...   \n",
       "901   r221102a_BOC          canada 2022-11-02   \n",
       "3245  r221103a_ECB       euro area 2022-11-03   \n",
       "3246  r221104b_ECB       euro area 2022-11-04   \n",
       "3247  r221104a_ECB       euro area 2022-11-04   \n",
       "4948  r221110a_SNB     switzerland 2022-11-10   \n",
       "\n",
       "                                                  title    author  is_gov  \\\n",
       "3221                                            NO_INFO      lane       0   \n",
       "6114  UK monetary policy in the context of global sp...      mann       0   \n",
       "3220  Hearing of the Committee on Economic and Monet...   lagarde       1   \n",
       "279                       Inflation and Monetary Policy      lowe       1   \n",
       "3222  Good, bad and hopeful news: the latest on the ...  elderson       0   \n",
       "...                                                 ...       ...     ...   \n",
       "901                  Preparing for payments supervision    morrow       0   \n",
       "3245  Mind the step: calibrating monetary policy in ...   panetta       0   \n",
       "3246    The euro area economy and the energy transition   guindos       0   \n",
       "3247  Monetary policy in a high inflation environmen...   lagarde       1   \n",
       "4948  Current challenges to central banks' independence    jordan       1   \n",
       "\n",
       "                                                   text  \\\n",
       "3221  Notes: The vertical line indicates the start o...   \n",
       "6114  Welcome to this presentation of the May . The ...   \n",
       "3220  It is a pleasure to be here again for our seco...   \n",
       "279   I would like to thank AMCHAM for the invitatio...   \n",
       "3222  I understand that today's audience includes ma...   \n",
       "...                                                 ...   \n",
       "901   Good morning, and thank you for inviting me to...   \n",
       "3245  The euro area is facing a sequence of unpreced...   \n",
       "3246  I am very pleased to be taking part in this ev...   \n",
       "3247  Inflation in the euro area is far too high, re...   \n",
       "4948  Ladies and gentlemen I am very grateful for th...   \n",
       "\n",
       "                                             keywords_1  \\\n",
       "3221            [hicp, forecast, gdp, hicpx, forecasts]   \n",
       "6114  [inflation, inflationary, shocks, monetary, ec...   \n",
       "3220  [euro, eurosystem, monetary, brussels, sanctions]   \n",
       "279     [inflation, inflationary, monetary, yield, cpi]   \n",
       "3222                [ecb, risks, risk, crises, climate]   \n",
       "...                                                 ...   \n",
       "901           [banks, bank, fintech, payments, payment]   \n",
       "3245  [inflationary, inflation, euro, eurosystem, mo...   \n",
       "3246  [inflation, macroeconomic, inflationary, econo...   \n",
       "3247  [inflation, inflationary, monetary, recessions...   \n",
       "4948  [macroeconomic, economists, economics, banks, ...   \n",
       "\n",
       "                                             keywords_2  \\\n",
       "3221  [hicpx quarterly, model hicp, hicp energy, hic...   \n",
       "6114  [shocks russia, shocks global, supply shocks, ...   \n",
       "3220  [affecting euro, monetary policy, relevant eur...   \n",
       "279   [current inflationary, ongoing inflation, rece...   \n",
       "3222  [risks climate, risks banks, practices ecb, cl...   \n",
       "...                                                 ...   \n",
       "901   [payments fintech, bank canada, finance canada...   \n",
       "3245  [inflation euro, risks inflation, risks euro, ...   \n",
       "3246  [energy inflation, economy following, economy ...   \n",
       "3247  [estonia inflation, exacerbate inflationary, i...   \n",
       "4948  [central banks, banks independence, bank indep...   \n",
       "\n",
       "                                             keywords_3  \n",
       "3221  [hicp energy prices, hicp hicpx quarterly, hea...  \n",
       "6114  [large shocks russia, shocks russia invasion, ...  \n",
       "3220  [facing monetary policy, severely affecting eu...  \n",
       "279   [responding higher inflation, inflation austra...  \n",
       "3222  [risk management ecb, risks practices ecb, ban...  \n",
       "...                                                 ...  \n",
       "901   [bank canada evolving, payments ecosystem cana...  \n",
       "3245  [euro reinforcing inflationary, risks inflatio...  \n",
       "3246  [inflation rising energy, euro area economy, e...  \n",
       "3247  [inflation entrenched euro, estonia inflation ...  \n",
       "4948  [central banks independence, central bank inde...  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = os.path.join(work_dir, \"OUTPUT/all_speeches_BERT.csv\")\n",
    "df_keywords_01.sort_values([\"country\",\"date\"]).to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.summary of full text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.summary of paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. text clustering: document level, sentence level, word level\n",
    "\n",
    "??? 每一条speech对应的一组keywords也可以vectorization ,对每一个speech 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yjy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries for preprocessing\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import webcolors\n",
    "\n",
    "#Download once if using NLTK for preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Libraries for vectorisation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from fuzzywuzzy import fuzz\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Libraries for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all keywords into a list\n",
    "li_keywords = []\n",
    "for i in df_keywords_01[\"keywords_1\"]:\n",
    "    for k in i:\n",
    "        li_keywords.append(k)\n",
    "\n",
    "\n",
    "# 1)Removing stopwords (punctuation and numbers)\n",
    "li_keywords_nonstop = [remove_stopwords(x) for x in li_keywords]\n",
    "\n",
    "# 2)Stemming and making words lower case\n",
    "li_keywords_stemmed = [PorterStemmer().stem(word) for word in li_keywords_nonstop]\n",
    "\n",
    "# 3)dedup\n",
    "li_keywords_clean = list(set(li_keywords_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "print(len(li_keywords_stemmed))\n",
    "print(len(li_keywords_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lender',\n",
       " 'inflationari',\n",
       " 'deposit',\n",
       " 'prospect',\n",
       " 'longev',\n",
       " 'ftf',\n",
       " 'mortgag',\n",
       " 'keynesian',\n",
       " 'hous',\n",
       " 'estim',\n",
       " 'portfolio',\n",
       " 'irish',\n",
       " 'decad',\n",
       " 'lisbon',\n",
       " 'sanction',\n",
       " 'nationalbank',\n",
       " 'insur',\n",
       " 'brunner',\n",
       " 'canadian',\n",
       " 'interest',\n",
       " 'policymak',\n",
       " 'crisi',\n",
       " 'wage',\n",
       " 'regul',\n",
       " 'hicp',\n",
       " 'market',\n",
       " 'tighten',\n",
       " 'document',\n",
       " 'economist',\n",
       " 'stabil',\n",
       " 'guidanc',\n",
       " 'ecb',\n",
       " 'basel',\n",
       " 'cryptocurr',\n",
       " 'studi',\n",
       " 'bundesbank',\n",
       " 'workforc',\n",
       " 'speech',\n",
       " 'spillov',\n",
       " 'eu',\n",
       " 'environment',\n",
       " 'bank',\n",
       " 'busi',\n",
       " 'ireland',\n",
       " 'merchant',\n",
       " 'disclosur',\n",
       " 'econom',\n",
       " 'cpi',\n",
       " 'fintech',\n",
       " 'qe',\n",
       " 'fiscal',\n",
       " 'overse',\n",
       " 'bi',\n",
       " 'ecosystem',\n",
       " 'student',\n",
       " 'recess',\n",
       " 'confidenti',\n",
       " 'disrupt',\n",
       " 'particip',\n",
       " 'save',\n",
       " 'yen',\n",
       " 'commerc',\n",
       " 'biodivers',\n",
       " 'energi',\n",
       " 'invest',\n",
       " 'currenc',\n",
       " 'mayor',\n",
       " 'yield',\n",
       " 'critic',\n",
       " 'belfast',\n",
       " 'eas',\n",
       " 'hurrican',\n",
       " 'brussel',\n",
       " 'shock',\n",
       " 'analyt',\n",
       " 'scotland',\n",
       " 'rural',\n",
       " 'sustain',\n",
       " 'welshman',\n",
       " 'analys',\n",
       " 'macroeconom',\n",
       " 'educ',\n",
       " 'forecast',\n",
       " 'climat',\n",
       " 'confer',\n",
       " 'hicpx',\n",
       " 'bitcoin',\n",
       " 'financi',\n",
       " 'welcom',\n",
       " 'massachusett',\n",
       " 'financ',\n",
       " 'tribe',\n",
       " 'natur',\n",
       " 'blockchain',\n",
       " 'award',\n",
       " 'pandem',\n",
       " 'find',\n",
       " 'assess',\n",
       " 'ecommerc',\n",
       " 'cryptoasset',\n",
       " 'tribal',\n",
       " 'economi',\n",
       " 'fluctuat',\n",
       " 'hobart',\n",
       " 'demand',\n",
       " 'innov',\n",
       " 'geopolit',\n",
       " 'iosco',\n",
       " 'secur',\n",
       " 'inform',\n",
       " 'franc',\n",
       " 'stablecoin',\n",
       " 'disturb',\n",
       " 'japan',\n",
       " 'monetari',\n",
       " 'crypto',\n",
       " 'rate',\n",
       " 'firm',\n",
       " 'decentr',\n",
       " 'governor',\n",
       " 'european',\n",
       " 'covid',\n",
       " 'banknot',\n",
       " 'liquid',\n",
       " 'age',\n",
       " 'inflat',\n",
       " 'eurosystem',\n",
       " 'anika',\n",
       " 'recessionari',\n",
       " 'consumpt',\n",
       " 'euro',\n",
       " 'household',\n",
       " 'friedman',\n",
       " 'banker',\n",
       " 'eurobaromet',\n",
       " 'payment',\n",
       " 'asset',\n",
       " 'polici',\n",
       " 'risk',\n",
       " 'gdp',\n",
       " 'crise',\n",
       " 'unemploy',\n",
       " 'regulatori',\n",
       " 'stakehold',\n",
       " 'snb',\n",
       " 'treasuri',\n",
       " 'consult',\n",
       " 'equiti',\n",
       " 'fed',\n",
       " 'commun',\n",
       " 'kansa',\n",
       " 'reinsur',\n",
       " 'retail',\n",
       " 'glasgow',\n",
       " 'reform']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_keywords_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "doc_embeddings, word_embeddings = kw_model.extract_embeddings(li_keywords_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007669</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>-0.042723</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>-0.030716</td>\n",
       "      <td>0.032587</td>\n",
       "      <td>0.053809</td>\n",
       "      <td>0.045713</td>\n",
       "      <td>-0.099437</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118522</td>\n",
       "      <td>-0.038261</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.039491</td>\n",
       "      <td>-0.008737</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>0.126518</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.079021</td>\n",
       "      <td>0.021028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020299</td>\n",
       "      <td>-0.052735</td>\n",
       "      <td>-0.041434</td>\n",
       "      <td>0.041596</td>\n",
       "      <td>-0.055858</td>\n",
       "      <td>-0.080565</td>\n",
       "      <td>0.117331</td>\n",
       "      <td>-0.033617</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060672</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>0.041681</td>\n",
       "      <td>-0.027955</td>\n",
       "      <td>0.104005</td>\n",
       "      <td>0.084475</td>\n",
       "      <td>0.066884</td>\n",
       "      <td>0.085888</td>\n",
       "      <td>-0.065285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003913</td>\n",
       "      <td>-0.039025</td>\n",
       "      <td>-0.092124</td>\n",
       "      <td>0.070361</td>\n",
       "      <td>-0.059062</td>\n",
       "      <td>-0.094265</td>\n",
       "      <td>0.125737</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.054019</td>\n",
       "      <td>-0.044649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117263</td>\n",
       "      <td>-0.037732</td>\n",
       "      <td>-0.047117</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>-0.007119</td>\n",
       "      <td>0.064494</td>\n",
       "      <td>0.044073</td>\n",
       "      <td>0.057410</td>\n",
       "      <td>0.101406</td>\n",
       "      <td>-0.062941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.109235</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>-0.053574</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>-0.116793</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>0.109918</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>-0.005617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035260</td>\n",
       "      <td>-0.063056</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.056082</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>0.118244</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>-0.066497</td>\n",
       "      <td>0.061425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016530</td>\n",
       "      <td>0.065246</td>\n",
       "      <td>-0.059178</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>0.102479</td>\n",
       "      <td>0.034086</td>\n",
       "      <td>-0.003677</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>-0.015691</td>\n",
       "      <td>0.033591</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>-0.082315</td>\n",
       "      <td>0.087509</td>\n",
       "      <td>0.170081</td>\n",
       "      <td>-0.012088</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.026955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.062230</td>\n",
       "      <td>-0.036790</td>\n",
       "      <td>-0.064798</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>-0.012884</td>\n",
       "      <td>-0.040325</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>-0.034958</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>0.037430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060020</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.020163</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>-0.006046</td>\n",
       "      <td>-0.030268</td>\n",
       "      <td>0.083941</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>-0.028527</td>\n",
       "      <td>-0.010323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.066800</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>-0.051866</td>\n",
       "      <td>-0.020900</td>\n",
       "      <td>-0.043303</td>\n",
       "      <td>-0.031882</td>\n",
       "      <td>0.109118</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.055153</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058547</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>-0.070201</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>-0.066535</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.089654</td>\n",
       "      <td>-0.022343</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>-0.008209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.153281</td>\n",
       "      <td>-0.062007</td>\n",
       "      <td>-0.123647</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>-0.057778</td>\n",
       "      <td>0.086930</td>\n",
       "      <td>-0.064630</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.008987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032244</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.040406</td>\n",
       "      <td>-0.016170</td>\n",
       "      <td>-0.125031</td>\n",
       "      <td>0.099414</td>\n",
       "      <td>0.063193</td>\n",
       "      <td>-0.032457</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>0.081170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.031799</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.071420</td>\n",
       "      <td>-0.065765</td>\n",
       "      <td>-0.055418</td>\n",
       "      <td>0.174168</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>-0.048308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046683</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>-0.035341</td>\n",
       "      <td>-0.066399</td>\n",
       "      <td>0.075709</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>-0.060029</td>\n",
       "      <td>-0.041129</td>\n",
       "      <td>-0.015920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.059840</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>-0.061918</td>\n",
       "      <td>0.046504</td>\n",
       "      <td>-0.011227</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.031553</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096363</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.013811</td>\n",
       "      <td>-0.019047</td>\n",
       "      <td>-0.004014</td>\n",
       "      <td>0.044266</td>\n",
       "      <td>-0.012086</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.156145</td>\n",
       "      <td>-0.012164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.007669  0.080905 -0.042723  0.011105 -0.030716  0.032587  0.053809   \n",
       "1    0.020299 -0.052735 -0.041434  0.041596 -0.055858 -0.080565  0.117331   \n",
       "2   -0.003913 -0.039025 -0.092124  0.070361 -0.059062 -0.094265  0.125737   \n",
       "3   -0.109235  0.018135 -0.053574  0.057518 -0.116793  0.025588  0.109918   \n",
       "4   -0.016530  0.065246 -0.059178  0.045026  0.032808  0.026994  0.102479   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "148 -0.062230 -0.036790 -0.064798  0.054597 -0.012884 -0.040325  0.110694   \n",
       "149 -0.066800  0.069039 -0.051866 -0.020900 -0.043303 -0.031882  0.109118   \n",
       "150 -0.153281 -0.062007 -0.123647  0.025149  0.056535 -0.057778  0.086930   \n",
       "151 -0.031799  0.063173  0.002367  0.071420 -0.065765 -0.055418  0.174168   \n",
       "152 -0.059840  0.078443 -0.061918  0.046504 -0.011227 -0.001546  0.036519   \n",
       "\n",
       "          7         8         9    ...       374       375       376  \\\n",
       "0    0.045713 -0.099437  0.033186  ...  0.118522 -0.038261 -0.001257   \n",
       "1   -0.033617  0.049723 -0.001540  ...  0.060672 -0.026018 -0.019445   \n",
       "2    0.005388  0.054019 -0.044649  ...  0.117263 -0.037732 -0.047117   \n",
       "3    0.012229  0.043151 -0.005617  ... -0.035260 -0.063056  0.025864   \n",
       "4    0.034086 -0.003677  0.054143  ...  0.010826 -0.015691  0.033591   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "148 -0.034958 -0.001344  0.037430  ...  0.060020 -0.001786 -0.020163   \n",
       "149 -0.083859 -0.055153  0.021494  ...  0.058547  0.002705 -0.070201   \n",
       "150 -0.064630  0.002154 -0.008987  ...  0.032244 -0.003096  0.040406   \n",
       "151  0.064084  0.011339 -0.048308  ...  0.046683 -0.000237 -0.028571   \n",
       "152  0.031553 -0.002532  0.013106  ...  0.096363 -0.000725 -0.013811   \n",
       "\n",
       "          377       378       379       380       381       382       383  \n",
       "0    0.039491 -0.008737  0.036098  0.126518  0.014899  0.079021  0.021028  \n",
       "1    0.041681 -0.027955  0.104005  0.084475  0.066884  0.085888 -0.065285  \n",
       "2    0.041648 -0.007119  0.064494  0.044073  0.057410  0.101406 -0.062941  \n",
       "3    0.056082  0.003503 -0.026018  0.118244 -0.009918 -0.066497  0.061425  \n",
       "4   -0.008973 -0.082315  0.087509  0.170081 -0.012088 -0.007832 -0.026955  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "148  0.001766 -0.006046 -0.030268  0.083941 -0.000551 -0.028527 -0.010323  \n",
       "149  0.037805 -0.066535  0.006799  0.089654 -0.022343  0.016591 -0.008209  \n",
       "150 -0.016170 -0.125031  0.099414  0.063193 -0.032457 -0.006803  0.081170  \n",
       "151 -0.035341 -0.066399  0.075709  0.068920 -0.060029 -0.041129 -0.015920  \n",
       "152 -0.019047 -0.004014  0.044266 -0.012086  0.000062  0.156145 -0.012164  \n",
       "\n",
       "[153 rows x 384 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_embeddings) # ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Word2Vec(use pretrained model??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word2Vec(li_keywords_clean,vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [w.wv.get_vector(str(n)) for n in w.wv.key_to_index],\n",
    "        index = w.wv.key_to_index\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lender',\n",
       " 'inflationari',\n",
       " 'deposit',\n",
       " 'prospect',\n",
       " 'longev',\n",
       " 'ftf',\n",
       " 'mortgag',\n",
       " 'keynesian',\n",
       " 'hous',\n",
       " 'estim',\n",
       " 'portfolio',\n",
       " 'irish',\n",
       " 'decad',\n",
       " 'lisbon',\n",
       " 'sanction',\n",
       " 'nationalbank',\n",
       " 'insur',\n",
       " 'brunner',\n",
       " 'canadian',\n",
       " 'interest',\n",
       " 'policymak',\n",
       " 'crisi',\n",
       " 'wage',\n",
       " 'regul',\n",
       " 'hicp',\n",
       " 'market',\n",
       " 'tighten',\n",
       " 'document',\n",
       " 'economist',\n",
       " 'stabil',\n",
       " 'guidanc',\n",
       " 'ecb',\n",
       " 'basel',\n",
       " 'cryptocurr',\n",
       " 'studi',\n",
       " 'bundesbank',\n",
       " 'workforc',\n",
       " 'speech',\n",
       " 'spillov',\n",
       " 'eu',\n",
       " 'environment',\n",
       " 'bank',\n",
       " 'busi',\n",
       " 'ireland',\n",
       " 'merchant',\n",
       " 'disclosur',\n",
       " 'econom',\n",
       " 'cpi',\n",
       " 'fintech',\n",
       " 'qe',\n",
       " 'fiscal',\n",
       " 'overse',\n",
       " 'bi',\n",
       " 'ecosystem',\n",
       " 'student',\n",
       " 'recess',\n",
       " 'confidenti',\n",
       " 'disrupt',\n",
       " 'particip',\n",
       " 'save',\n",
       " 'yen',\n",
       " 'commerc',\n",
       " 'biodivers',\n",
       " 'energi',\n",
       " 'invest',\n",
       " 'currenc',\n",
       " 'mayor',\n",
       " 'yield',\n",
       " 'critic',\n",
       " 'belfast',\n",
       " 'eas',\n",
       " 'hurrican',\n",
       " 'brussel',\n",
       " 'shock',\n",
       " 'analyt',\n",
       " 'scotland',\n",
       " 'rural',\n",
       " 'sustain',\n",
       " 'welshman',\n",
       " 'analys',\n",
       " 'macroeconom',\n",
       " 'educ',\n",
       " 'forecast',\n",
       " 'climat',\n",
       " 'confer',\n",
       " 'hicpx',\n",
       " 'bitcoin',\n",
       " 'financi',\n",
       " 'welcom',\n",
       " 'massachusett',\n",
       " 'financ',\n",
       " 'tribe',\n",
       " 'natur',\n",
       " 'blockchain',\n",
       " 'award',\n",
       " 'pandem',\n",
       " 'find',\n",
       " 'assess',\n",
       " 'ecommerc',\n",
       " 'cryptoasset',\n",
       " 'tribal',\n",
       " 'economi',\n",
       " 'fluctuat',\n",
       " 'hobart',\n",
       " 'demand',\n",
       " 'innov',\n",
       " 'geopolit',\n",
       " 'iosco',\n",
       " 'secur',\n",
       " 'inform',\n",
       " 'franc',\n",
       " 'stablecoin',\n",
       " 'disturb',\n",
       " 'japan',\n",
       " 'monetari',\n",
       " 'crypto',\n",
       " 'rate',\n",
       " 'firm',\n",
       " 'decentr',\n",
       " 'governor',\n",
       " 'european',\n",
       " 'covid',\n",
       " 'banknot',\n",
       " 'liquid',\n",
       " 'age',\n",
       " 'inflat',\n",
       " 'eurosystem',\n",
       " 'anika',\n",
       " 'recessionari',\n",
       " 'consumpt',\n",
       " 'euro',\n",
       " 'household',\n",
       " 'friedman',\n",
       " 'banker',\n",
       " 'eurobaromet',\n",
       " 'payment',\n",
       " 'asset',\n",
       " 'polici',\n",
       " 'risk',\n",
       " 'gdp',\n",
       " 'crise',\n",
       " 'unemploy',\n",
       " 'regulatori',\n",
       " 'stakehold',\n",
       " 'snb',\n",
       " 'treasuri',\n",
       " 'consult',\n",
       " 'equiti',\n",
       " 'fed',\n",
       " 'commun',\n",
       " 'kansa',\n",
       " 'reinsur',\n",
       " 'retail',\n",
       " 'glasgow',\n",
       " 'reform']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_keywords_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 PCA&k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Stemming and making words lower case\n",
    "\n",
    "# kmeans\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
